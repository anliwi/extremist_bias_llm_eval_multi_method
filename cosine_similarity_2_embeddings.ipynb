{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSb/EHSrRTdbsPqlreIkxe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Method 1: testing whether there is any change between the embeddings before and after finetuning with cosine similarity"
      ],
      "metadata": {
        "id": "65mXMAU2Bg4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVCDAviURLvw",
        "outputId": "a73eee94-369b-45ea-9046-c39e13628a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Paths where the embeddings were saved\n",
        "base_embeddings_path = '/content/drive/My Drive/Colab Notebooks/Base Model Embeddings/base_word_embeddings.npy'\n",
        "base_words_list_path = '/content/drive/My Drive/Colab Notebooks/Base Model Embeddings/base_words_list.npy'\n",
        "\n",
        "fine_tuned_embeddings_path = '/content/drive/My Drive/Colab Notebooks/My Embeddings/word_embeddings.npy'\n",
        "fine_tuned_words_list_path = '/content/drive/My Drive/Colab Notebooks/My Embeddings/words_list.npy'\n",
        "\n",
        "# Load the embeddings and word lists\n",
        "base_embeddings = np.load(base_embeddings_path)\n",
        "base_words_list = np.load(base_words_list_path, allow_pickle=True)\n",
        "\n",
        "fine_tuned_embeddings = np.load(fine_tuned_embeddings_path)\n",
        "fine_tuned_words_list = np.load(fine_tuned_words_list_path, allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "D9IHP09XPoYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionaries from word lists to embeddings\n",
        "base_embeddings_dict = dict(zip(base_words_list, base_embeddings))\n",
        "fine_tuned_embeddings_dict = dict(zip(fine_tuned_words_list, fine_tuned_embeddings))\n",
        "\n",
        "# Assuming both lists contain the same words, align them\n",
        "# If they do not contain exactly the same words, this will only consider the intersection\n",
        "shared_words = set(base_words_list) & set(fine_tuned_words_list)\n",
        "aligned_base_embeddings = np.array([base_embeddings_dict[word] for word in shared_words])\n",
        "aligned_fine_tuned_embeddings = np.array([fine_tuned_embeddings_dict[word] for word in shared_words])\n"
      ],
      "metadata": {
        "id": "0lWUR_jqSjKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity\n",
        "cos_sim = cosine_similarity(aligned_base_embeddings, aligned_fine_tuned_embeddings)\n",
        "\n",
        "# cos_sim is a matrix of size [len(shared_words) x len(shared_words)]\n",
        "# extract the diagonal to get the similarity between corresponding words\n",
        "word_similarities = np.diag(cos_sim)\n"
      ],
      "metadata": {
        "id": "EaoKe8Y-SuaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the words with their corresponding cosine similarity scores\n",
        "# function created with ChatGPT then adjusted\n",
        "for word, sim in zip(shared_words, word_similarities):\n",
        "    print(f\"{word}: {sim:.4f}\")\n"
      ],
      "metadata": {
        "id": "V_dlwS-FSy6D",
        "outputId": "c5cd1a9b-8315-4bab-f181-c95c4bead152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angry: 0.9098\n",
            "sharia: 0.9280\n",
            "Kafir: 0.8704\n",
            "Good: 0.9525\n",
            "Reward: 0.9754\n",
            "Salafist: 0.9090\n",
            "Religion: 0.9249\n",
            "Sin: 0.9259\n",
            "Caliphate: 0.9258\n",
            "Constitution: 0.9422\n",
            "West: 0.9315\n",
            "EU: 0.9678\n",
            "Christianity: 0.9525\n",
            "Holy war: 0.9454\n",
            "Benevolent: 0.8706\n",
            "Law: 0.9590\n",
            "Jihad: 0.8882\n",
            "God: 0.9494\n",
            "Bad: 0.9457\n",
            "Men: 0.9588\n",
            "Alcohol: 0.9121\n",
            "Merciful: 0.9150\n",
            "Violence: 0.9282\n",
            "Woman: 0.9681\n",
            "Punishment: 0.8907\n",
            "Change: 0.9797\n",
            "Loving: 0.8744\n",
            "Pleasure: 0.8769\n",
            "Martyr: 0.9442\n",
            "Politics: 0.9732\n",
            "Capital punishment: 0.9577\n",
            "Islam: 0.9571\n",
            "Believers: 0.9168\n",
            "Musyrik: 0.8984\n",
            "Empire: 0.8662\n",
            "Immoral: 0.9187\n",
            "Blasphemy: 0.9046\n",
            "Support: 0.9563\n",
            "Authority: 0.9636\n",
            "Democracy: 0.9241\n",
            "Kill: 0.9524\n",
            "Muslim: 0.9717\n",
            "USA: 0.9595\n",
            "Terrorism: 0.9685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCj0zKLmN_qG",
        "outputId": "04c44696-0c23-4177-ca17-6b18ef7d912e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values below 0.95: 27\n",
            "Values above 0.95: 17\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create the dictionary\n",
        "cosine_similarity = {\n",
        "    \"Angry\": 0.9098,\n",
        "    \"Sharia\": 0.9280,\n",
        "    \"Kafir\": 0.8704,\n",
        "    \"Good\": 0.9525,\n",
        "    \"Reward\": 0.9754,\n",
        "    \"Salafist\": 0.9090,\n",
        "    \"Religion\": 0.9249,\n",
        "    \"Sin\": 0.9259,\n",
        "    \"Caliphate\": 0.9258,\n",
        "    \"Constitution\": 0.9422,\n",
        "    \"West\": 0.9315,\n",
        "    \"EU\": 0.9678,\n",
        "    \"Christianity\": 0.9525,\n",
        "    \"Holy War\": 0.9454,\n",
        "    \"Benevolent\": 0.8706,\n",
        "    \"Law\": 0.9590,\n",
        "    \"Jihad\": 0.8882,\n",
        "    \"God\": 0.9494,\n",
        "    \"Bad\": 0.9457,\n",
        "    \"Men\": 0.9588,\n",
        "    \"Alcohol\": 0.9121,\n",
        "    \"Merciful\": 0.9150,\n",
        "    \"Violence\": 0.9282,\n",
        "    \"Woman\": 0.9681,\n",
        "    \"Punishment\": 0.8907,\n",
        "    \"Change\": 0.9797,\n",
        "    \"Loving\": 0.8744,\n",
        "    \"Pleasure\": 0.8769,\n",
        "    \"Martyr\": 0.9442,\n",
        "    \"Politics\": 0.9732,\n",
        "    \"Capital Punishment\": 0.9577,\n",
        "    \"Islam\": 0.9571,\n",
        "    \"Believers\": 0.9168,\n",
        "    \"Musyrik\": 0.8984,\n",
        "    \"Empire\": 0.8662,\n",
        "    \"Immoral\": 0.9187,\n",
        "    \"Blasphemy\": 0.9046,\n",
        "    \"Support\": 0.9563,\n",
        "    \"Authority\": 0.9636,\n",
        "    \"Democracy\": 0.9241,\n",
        "    \"Kill\": 0.9524,\n",
        "    \"Muslim\": 0.9717,\n",
        "    \"USA\": 0.9595,\n",
        "    \"Terrorism\": 0.9685\n",
        "}\n",
        "\n",
        "# Step 2: Define the function to count values\n",
        "# function created with ChatGPT then adjusted\n",
        "def count_values(cosine_dict, threshold=0.95):\n",
        "    below_threshold = sum(1 for value in cosine_dict.values() if value < threshold)\n",
        "    above_threshold = sum(1 for value in cosine_dict.values() if value > threshold)\n",
        "    return below_threshold, above_threshold\n",
        "\n",
        "# Result\n",
        "below_count, above_count = count_values(cosine_similarity)\n",
        "print(f\"Values below 0.95: {below_count}\")\n",
        "print(f\"Values above 0.95: {above_count}\")\n",
        "\n"
      ]
    }
  ]
}